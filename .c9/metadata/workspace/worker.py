{"changed":true,"filter":false,"title":"worker.py","tooltip":"/worker.py","value":"#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Copyright 2007 Google Inc.\n#\n# Data sources:\n# http://www.ehp.qld.gov.au/cgi-bin/air/xml.php?category=1&region=ALL\n# http://campodenno.taslab.eu/stazioni/json?id=CMD001\n# coding=utf-8\n\"\"\"\nNY - 40.714224,-73.961452\nSP - -23.560057,-46.634334\nGBG - 57.70887,11.97456\nBER - 52.536958,13.408041\nHTULL -\nSOFO - 59.312963,18.080363\nHarajuku - 35.671628,139.710285\nWellington - -41.296435,174.776527\nSidney - -33.896549,151.179963\nKitazawa - 35.663365,139.668332\nNairobi - -1.282794,36.828232\nCanary Warf, London - 51.501538, -0.015757\n\nBarrsatra - 60.620428,16.750116\nNew Holland/Admiralteysky District St Petersburg - 59.929506,30.289360\nData from http://luft.hamburg.de/\n24FL - 53.638128,9.996872\n70MB - 53.555555,9.943407\n17SM - 53.560899,9.957213\n68HB - 53.592354,10.053774\n61WB -\n\nEAA\nhttp://fme.discomap.eea.europa.eu/fmedatastreaming/AirQuality/AirQualityUTDExport.fmw?FromDate=2015-03-17&ToDate=2015-03-17&Countrycode=se&InsertedSinceDate=&UpdatedSinceDate=&Pollutant=PM10,SO2,NO2,CO&Namespace=&Format=XML&UserToken=6C2D03D8-04E1-4D07-B856-D92ACE0FA832\n\"\"\"\n\n\"\"\"\nDeploy:\ngit add . && git commit -m 'Some stuff' && git push && gcloud -q app deploy --version=primary\n\nupdate cron: \ngcloud app deploy cron.yaml\n\n\"\"\"\nimport sys\nsys.path.insert(0, 'libs')\nimport os\nimport ast\nimport logging\nimport jinja2\nimport webapp2\nimport json\nimport urllib\nimport urllib2\nimport base64\nfrom google.appengine.api import taskqueue\nfrom google.appengine.ext import db\nfrom google.appengine.api import urlfetch\nfrom google.appengine.api import memcache\nfrom protorpc import messages\nfrom protorpc import message_types\nfrom protorpc import remote\nfrom random import randrange\nimport datetime\nimport calendar\nimport time\nimport csv\nimport StringIO\nimport json\nimport re\nfrom xml.dom import minidom\nfrom google.appengine.ext import db\nimport hashlib\nimport yaml\nfrom bs4 import BeautifulSoup\n#from httplib2 import Http\n#from oauth2client.service_account import ServiceAccountCredentials\n#from apiclient.discovery import build\n#import requests\n\n#GEOLOCATION_URL = \"https://maps.googleapis.com/maps/api/geocode/json?language=en&key=AIzaSyDTr4jvDt3ZM1Nv68mMR_mcw8TxyQV7x5k&latlng=%s\"\nGEOLOCATION_URL = \"https://maps.googleapis.com/maps/api/geocode/json?language=en&key=AIzaSyAZQS_TBcZ2XNhApQttypDRarDWcy_phG4&latlng=%s\"\n\n# http://apis-explorer.appspot.com/apis-explorer/?base=http://localhost:8080/_ah/api#p/\n\nJINJA_ENVIRONMENT = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(__file__)),extensions=['jinja2.ext.autoescape'],autoescape=True)\nFOOBOT_LOCATIONS = {\n  \"flintbacken10\": \"59.310014,18.050748\",\n  \"Bondegatan21-Ugnen\": \"59.312963,18.080363\",\n  \"HappyWattBot05Bergsunds Strand\": \"59.316569,18.026894\",\n  \"Peringskioldsvagen58\": \"59.35111,17.90213\",\n  \"cykelfabriken\": \"59.311971,18.082123\",\n  \"LBK\": \"59.313408,18.033371\",\n  \"Pauls_dagis\": \"59.310029,18.047490\",\n  \"fargfabriken_utebar\":\"59.314924,18.019890\",\n  \"Peringv58_VerifyPaul\":\"59.35111,17.90213\",\n  \"Atterbomsvagen\":\"59.3273015,18.0088859\"\n}\n\n\nclass AirReport(): pass\nclass HoodReport(): pass\n\nclass Report(db.Model):\n    zoneKey = db.StringProperty()\n    name = db.StringProperty()\n    report = db.TextProperty()\n\nclass Records(db.Model):\n    \"\"\"Models an individual Record entry with content and date.\"\"\"\n    timestamp = db.DateTimeProperty()\n    pm10 = db.FloatProperty()\n    pm25 = db.FloatProperty()\n    o3 = db.FloatProperty()\n    co = db.FloatProperty()\n    no2 = db.FloatProperty()\n    index = db.FloatProperty()\n    position = db.GeoPtProperty()\n    positionLabels = db.StringProperty()\n    sourceId = db.StringProperty()\n    zoneKey = db.StringProperty()\n\n\n\nclass Bot(webapp2.RequestHandler):\n    def get(self):\n        postdata = {}\n        postdata['sourceId'] = \"BotFargfabriken\"\n        postdata['position'] = \"59.31472280000001,18.02025470000001\"\n        postdata['pm10'] = '22' # Should be a bit random\n        taskqueue.add(url='/worker', params=postdata)\n        self.response.write(postdata)\n\n\n\n\n#http://www.airnowapi.org/aq/data/?startDate=2016-05-15T22&endDate=2016-05-15T23&parameters=O3,PM25,PM10,CO,NO2,SO2&BBOX=-124.205070,28.716781,-75.337882,45.419415&dataType=B&format=application/json&verbose=0&API_KEY=0A8FF804-8227-4C80-A150-A495616F30DB\nclass Airnow(webapp2.RequestHandler):\n    def get(self):\n        isonowinUsa = datetime.datetime.now() - datetime.timedelta(hours=1)\n        isotoday = isonowinUsa.date().isoformat()\n        hour = isonowinUsa.hour\n        url = \"http://www.airnowapi.org/aq/data/?startDate=\" + isotoday + \"T\" + str(hour) + \"&endDate=\" + isotoday + \"T\" + str(hour+1) + \"&parameters=O3,PM25,PM10,CO,NO2&BBOX=-124.205070,28.716781,-75.337882,45.419415&dataType=B&format=application/json&verbose=0&API_KEY=0A8FF804-8227-4C80-A150-A495616F30DB\"\n        #url = \"http://www.airnowapi.org/aq/data/?startDate=2016-05-15T22&endDate=2016-05-15T23&parameters=PM25,PM10&BBOX=-116.938171,27.476288,-73.520203,43.154850&dataType=B&format=application/json&verbose=0&API_KEY=0A8FF804-8227-4C80-A150-A495616F30DB\"\n        print url\n        self.response.write(url)\n\n        urlfetch.set_default_fetch_deadline(600)\n        headers = {'Accept':'application/json;charset=UTF-8','Content-Type':'application/json'}\n        result = urlfetch.fetch(\n            url,\n            headers=headers,\n            method='GET'\n        )\n        try:\n            #hashlib.md5(zoneKeyInputString.encode('ascii', 'ignore').decode('ascii')).hexdigest()\n            data = json.loads(result.content)\n            for obj in data:\n                postdata = {}\n                #{u'Category': 1, u'Longitude': -123.64835, u'UTC': u'2016-05-15T22:00', u'Parameter': u'PM2.5', u'AQI': 7, u'Latitude': 42.1617, u'Value': 1.6, u'Unit': u'UG/M3'},\n                lat = obj['Latitude']\n                lon = obj['Longitude']\n                \n\n                position = str(lat) + \",\" + str(lon)\n                \n                \n                sourceId = \"AirNow\" + hashlib.md5(position.encode('ascii', 'ignore').decode('ascii')).hexdigest()\n                self.response.write(\"<p>\" + sourceId + \" - \" + position + \"</p>\")\n                parameter = obj['Parameter']\n                if parameter == 'OZONE':\n                    parameter = parameter.replace('OZONE', 'o3')\n                value = str(obj['Value'])\n                postdata['sourceId'] = sourceId\n                postdata['position'] = position\n                postdata[parameter.lower()] = value\n                taskqueue.add(url='/worker', params=postdata)\n\n            self.response.write(data)\n\n        except Exception, e:\n            self.response.write(e)\n\nclass Linkoping(webapp2.RequestHandler):\n    def get(self):\n        isotoday = datetime.datetime.now().date().isoformat()\n        url = \"http://nods.se/rest/air/municipalities/0580?from=\" + isotoday + \"&minified=true\"\n        print url\n        headers = {'Accept':'application/json;charset=UTF-8','Content-Type':'application/json'}\n        result = urlfetch.fetch(\n            url,\n            headers=headers,\n            method='GET'\n        )\n        try:\n            data = json.loads(result.content)\n            dataLatest = data['airMeasurements'][0]\n            postdata = {}\n            time = dataLatest[\"time\"]\n            pm = dataLatest[\"value\"]\n            sourceId = \"Linkoping-hamngatan-nods\"\n            postdata['sourceId'] = sourceId\n            postdata['position'] = \"58.408413,15.631572\"\n            postdata['pm10'] = str(pm)\n            taskqueue.add(url='/worker', params=postdata)\n            self.response.write(postdata)\n\n        except Exception, e:\n            self.response.write(\"no data available: \" + url)\n\nclass Foobot(webapp2.RequestHandler):\n    def get(self):\n        isotoday = datetime.datetime.now().date().isoformat()\n        print isotoday\n        #urlLogin = 'https://api.foobot.io/v2/user/lars@wattsgard.se/login/'\n        urlLogin = 'http://api-eu-west-1.foobot.io/v2/user/lars%40wattsgard.se/login/'\n\n        urlDevice = 'https://api-eu-west-1.foobot.io/v2/owner/lars%40wattsgard.se/device/'\n        urlData = 'https://api-eu-west-1.foobot.io/v2/device/%s/datapoint/'+ isotoday + 'T00:00/' + isotoday + 'T23:59:00/0/'\n        urlfetch.set_default_fetch_deadline(60)\n        # First. Login and get the token\n        base64string = base64.encodestring('%s:%s' % (\"lars@wattsgard.se\", \"AirUp123\")).replace('\\n', '')\n        headers = {'Accept':'application/json;charset=UTF-8','Content-Type':'application/json'}\n\n        payload=\"{\\\"password\\\":\\\"AirUp123\\\"}\"\n        resLogin = urlfetch.fetch(\n            urlLogin,\n            headers=headers,\n            method='POST',\n            payload=payload\n        )\n\n        if resLogin.status_code == 200:\n            token = resLogin.headers['X-AUTH-TOKEN']\n            # 2 use the token to get all devices\n            headers = {'Accept':'application/json;charset=UTF-8','Content-Type':'application/json','X-AUTH-TOKEN': token}\n            responseDev = urlfetch.fetch(\n                urlDevice,\n                method='GET',\n                headers = headers\n            )\n            devices = json.loads(responseDev.content)\n            for dev in devices:\n                postdata = {}\n                # 3. using each device uuid get all data (within the dates)\n                #self.response.write(dev)\n                #print dev['uuid']\n                responseData = urlfetch.fetch(url=urlData % dev['uuid'], method = urlfetch.GET, headers = {\"X-AUTH-TOKEN\": token})\n                fooData = responseData.content\n                #self.response.write(fooData)\n                headers = (\"s\",\n                    \"ugm3\",\n                    \"C\",\n                    \"pc\",\n                    \"ppm\",\n                    \"ppb\",\n                    \"%\")\n                j = json.loads(fooData)\n                dp = j['datapoints']\n\n                if dp:\n                    latest = dp[0]\n                    if latest:\n                        postdata = {}\n                        time = latest[0]\n                        pm = latest[1]\n                        sourceId = dev['name'].strip()\n                        postdata['sourceId'] = sourceId\n                        postdata['position'] = FOOBOT_LOCATIONS[sourceId]\n                        postdata['pm25'] = str(pm)\n                        taskqueue.add(url='/worker', params=postdata)\n                        self.response.write(postdata)\n        else:\n            self.response.write(resLogin.content)\n\n#http://www.stateair.net/web/rss/1/1.xml\nclass Stateair(webapp2.RequestHandler):\n\n    def get(self):\n\n        def getText(nodelist):\n            rc = []\n            for node in nodelist:\n                if node.nodeType == node.TEXT_NODE:\n                    rc.append(node.data)\n            return ''.join(rc).encode(\"utf-8\",\"ignore\")\n\n        def regData(url, sourceId, position):\n\n            response = urllib2.urlopen(url, timeout = 90)\n            xmldoc = minidom.parse(response)\n            items = xmldoc.getElementsByTagName('item')\n            latestItem = items[0]\n            conc = latestItem.getElementsByTagName(\"Conc\")[0]\n            postdata = {}\n            postdata['sourceId'] = sourceId\n            postdata['position'] = position\n            postdata['pm25'] = str(getText(conc.childNodes))\n            self.response.write(postdata)\n            taskqueue.add(url='/worker', params=postdata)\n\n        regData(\"http://www.stateair.net/web/rss/1/1.xml\", \"StateairBeijing\", \"39.904211,116.407395\")\n        regData(\"http://www.stateair.net/web/rss/1/2.xml\", \"StateairChengdu\", \"30.572816,104.066801\")\n        regData(\"http://www.stateair.net/web/rss/1/3.xml\", \"StateairGuangzhou\", \"23.129110,113.264385\")\n        regData(\"http://www.stateair.net/web/rss/1/4.xml\", \"StateairShanghai\", \"31.230416,121.473701\")\n        regData(\"http://www.stateair.net/web/rss/1/5.xml\", \"StateairShenyang\", \"41.805699,123.431472\")\n        regData(\"https://stateair.mn/rss.xml\", \"StateairUlanBator\", \"47.886399,106.905744\")\n\n\n\nclass Eaa(webapp2.RequestHandler):\n\n    def get(self):\n\n        def regData(country):\n            isotoday = datetime.datetime.now().date().isoformat()\n            url = \"http://fme.discomap.eea.europa.eu/fmedatastreaming/AirQuality/AirQualityUTDExport.fmw?FromDate=\" + isotoday + \"&ToDate=\" + isotoday + \"&Countrycode=\" + country + \"&InsertedSinceDate=&UpdatedSinceDate=&Pollutant=PM10&Namespace=&Format=XML&UserToken=6C2D03D8-04E1-4D07-B856-D92ACE0FA832\"\n            response = urllib2.urlopen(url, timeout = 90)\n            xmldoc = minidom.parse(response)\n            records = xmldoc.getElementsByTagName('record')\n            self.response.write(\"<br/><code>\" + url + \" - \" + str(len(records)) + \" <code><br/>\")\n\n            def getText(nodelist):\n                rc = []\n                for node in nodelist:\n                    if node.nodeType == node.TEXT_NODE:\n                        rc.append(node.data)\n                return ''.join(rc).encode(\"utf-8\",\"ignore\")\n\n            for rec in records:\n                postdata = {}\n                station_code = rec.getElementsByTagName(\"station_code\")[0]\n                station_name = rec.getElementsByTagName(\"station_name\")[0]\n                pollutant = rec.getElementsByTagName(\"pollutant\")[0]\n                samplingpoint_point = rec.getElementsByTagName(\"samplingpoint_point\")[0]\n                value_numeric = rec.getElementsByTagName(\"value_numeric\")[0]\n                posx = samplingpoint_point.attributes['x'].value\n                posy = samplingpoint_point.attributes['y'].value\n                sourceId = \"EAA-\"+getText(station_code.childNodes)\n                postdata['sourceId'] = sourceId\n                postdata['position'] = posy + \",\" + posx\n                postdata[getText(pollutant.childNodes).lower()] = str(getText(value_numeric.childNodes))\n                self.response.write(postdata)\n                taskqueue.add(url='/worker', params=postdata)\n\n\n        country = self.request.get('country')\n        regData(country)\n        self.response.write(\"<br/><code>EAA DONE<code><br/>\")\n\n\n\nclass Hamburg1(webapp2.RequestHandler):\n\n    def get(self):\n        #print \"HBG\"\n\n        def regData(url, sourceId, position):\n\n            response = urllib2.urlopen(url)\n            cr = csv.reader(response)\n            postdata = {\n                'sourceId': sourceId,\n                'position': position,\n                'pm10': '',\n                'pm25': '',\n                'o3': '',\n                'co': '',\n                'no2': ''\n            }\n            rlista = list(cr)[5]\n            co = rlista[1]\n\n            try:\n                co = rlista[1]\n                postdata['co'] = str(((float(co))*24.4500)/28.0100) #Convert mg/m3 to ppm\n            except Exception, e:\n                print \"No co\"\n\n            try:\n                no2 = rlista[3]\n                postdata['no2'] = str(((float(no2)/1000.0000)*24.4500)/46.0100) #Convert mg/m3 to ppm\n            except Exception, e:\n                print \"No no2\"\n\n\n\n            #postdata['sourceId'] = sourceId\n            #postdata['position'] = position\n\n            self.response.write(\"<br/><code>DONE \" + sourceId + \"<code><br/>\")\n            taskqueue.add(url='/worker', params=postdata)\n\n        \"\"\"\n        Data from http://luft.hamburg.de/\n        \"\"\"\n        regData(\"http://hamburg.luftmessnetz.de/station/70MB.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-70MB\", \"53.555555,9.943407\")\n        regData(\"http://hamburg.luftmessnetz.de/station/17SM.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-17SM\", \"53.560899,9.957213\")\n        #regData(\"http://hamburg.luftmessnetz.de/station/68HB.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-68HB\", \"53.592354,10.053774\")\n        regData(\"http://hamburg.luftmessnetz.de/station/24FL.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-24FL\", \"53.638128,9.996872\")\n        regData(\"http://hamburg.luftmessnetz.de/station/61WB.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-61WB\", \"53.508315,9.990633\")\n        regData(\"http://hamburg.luftmessnetz.de/station/13ST.csv?componentgroup=pollution&componentperiod=1h&searchperiod=currentday\",\"Hamburg-13ST\", \"53.562087,9.964416\")\n\nclass Goteborg(webapp2.RequestHandler):\n\n    def get(self):\n        url = \"http://data.goteborg.se/AirQualityService/v1.0/LatestMeasurement/4abad3dd-5d24-4c9c-9d17-79a946abe6c2?format=json\"\n        response = urllib2.urlopen(url);\n        data = json.loads(response.read())\n        sourceId = \"GBG1\"\n        postdata = {\n            'sourceId': sourceId,\n            'position': '57.708870,11.974560',\n            'pm10': '',\n            'pm25': '',\n            'o3': '',\n            'co': '',\n            'no2': ''\n        }\n        try:\n        \tpm10 = data['AirQuality']['PM10']['Value']\n        \tpostdata.pm10 = str(pm10)\n        except Exception, e:\n        \tprint \"no pm10\"\n        \t#postdata['pm10'] = 0\n\n        try:\n        \tno2 = data['AirQuality']['NO2']['Value']\n        \tpostdata.no2 = str(((no2/1000.0000)*24.4500)/46.0100) #Convert mg/m3 to ppm\n        except Exception, e:\n        \tprint \"No no2\"\n        \t#postdata['no2'] = 0\n\n        try:\n        \tco = data['AirQuality']['CO']['Value']\n        \tpostdata.co = str(((co/1000.0000)*24.4500)/28.0100) #Convert mg/m3 to ppm\n        except Exception, e:\n        \tprint \"No co\"\n        \t#postdata['co'] = 0\n\n\n        taskqueue.add(url='/worker', params=postdata)\n\n        self.response.write(postdata)\n\n\n\nclass SubmitToQueue(webapp2.RequestHandler):\n\n    def post(self):\n\n        postdata = {}\n\n        try:\n            pm10=self.request.get('pm10')\n            postdata['pm10'] = str(pm10)\n        except Exception, e:\n            print \"no pm10\"\n\n        try:\n            pm25=self.request.get('pm25')\n            postdata['pm25'] = str(pm25)\n        except Exception, e:\n            print \"no pm25\"\n\n        try:\n            o3=self.request.get('o3')\n            postdata['o3'] = str(o3)\n        except Exception, e:\n            print \"No o3\"\n\n        try:\n            no2=self.request.get('no2')\n            postdata['no2'] = str(no2)\n        except Exception, e:\n            print \"No no2\"\n\n        try:\n            co=self.request.get('co')\n            postdata['co'] = str(co)\n        except Exception, e:\n            print \"No co\"\n\n        try:\n            sourceId=self.request.get('sourceId')\n            postdata['sourceId'] = sourceId\n        except Exception, e:\n            print \"No sourceId\"\n\n        try:\n            lat=self.request.get('lat')\n            lon=self.request.get('lon')\n            postdata['position'] = lat + ',' + lon\n        except Exception, e:\n            print \"No position\"\n\n\n        self.response.write(postdata)\n\n        taskqueue.add(url='/worker', params=postdata)\n\n\n\nclass Umea(webapp2.RequestHandler):\n    def get(self):\n        #print \"#### UMEA ####\"\n    \t#logging.info(\"UMEA\")\n    \turl = \"http://ckan.openumea.se/api/action/datastore_search?resource_id=27fb8bcc-23cb-4e85-b5b4-fde68a8ef93a&limit=1&sort=M%C3%A4ttidpunkt%20desc\"\n        try:\n            response = urllib2.urlopen(url);\n            data = json.loads(response.read())\n        except Exception, e:\n            print \"Error\"\n\n    \t#postdata = {}\n    \ttry:\n    \t\tpm10 = data['result']['records'][0]['PM10']\n    \t\t#postdata['pm10'] = str(float(pm10))\n    \texcept Exception, e:\n    \t\tpm10 = 0\n\n        pm10str = str(float(pm10))\n\n    \ttry:\n    \t\tno2 = data['result']['records'][0]['NO2']\n    \t\t#postdata['no2'] = str(((no2/1000.0000)*24.4500)/46.0100) #Convert mg/m3 to ppm\n    \texcept Exception, e:\n    \t\tno2 = 0\n\n        no2str = str(((no2/1000.0000)*24.4500)/46.0100)\n        sourceId = 'UMEA1'\n        payload = {\n            'sourceId': sourceId,\n            'position': '63.827743,20.256825',\n            'pm10': pm10str,\n            'pm25': '',\n            'o3': '',\n            'no2': no2str\n        }\n\n        taskqueue.add(url='/worker', params=payload)\n    \tself.response.write(payload)\n\nclass Sthlm(webapp2.RequestHandler):\n    def get(self):\n        SLB_LOCATIONS = {\n          \"Hornsgatan\": \"59.310014,18.050748\",\n          \"Folkungagatan\": \"59.312963,18.080363\",\n          \"Lilla Essingen (E4/E20)\": \"59.316569,18.026894\",\n          \"Södertälje Turingegatan\": \"59.35111,17.90213\",\n          \"Uppsala Kungsgatan\": \"59.311971,18.082123\",\n          \"Gävle Södra Kungsgatan\": \"59.313408,18.033371\"\n        }\n        SLB_POLLUTANT = [\"pm10\", \"pm25\", \"no2\", \"o3\"]\n\n        def find_between( s, first, last ):\n            try:\n                start = s.index( first ) + len( first )\n                end = s.index( last, start )\n                return s[start:end]\n            except ValueError:\n                return \"\"\n\n        url = \"http://slb.nu/slbanalys/luften-idag/\"\n        headers = {'Accept':'text/html;charset=UTF-8','Content-Type':'text/html'}\n        result = urlfetch.fetch(\n            url,\n            headers=headers,\n            method='GET'\n        )\n        soup = BeautifulSoup(result.content, 'html.parser')\n        scripts = soup.find_all('script')\n        start = \"var data = google.visualization.arrayToDataTable(\"\n        end = \");\"\n        slbLocations = {\n          \"Hornsgatan\": {'sourceId': 'SLB-Hornsgatan','position': '59.317242,18.049891','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Folkungagatan\": {'sourceId': 'SLB-Folkungagatan','position': '59.314508,18.075318','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Lilla Essingen (E4/E20)\": {'sourceId': 'SLB-Lilla Essingen','position': '59.325304,18.00296','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Södertälje Turingegatan\": {'sourceId': 'SLB-Sodertalje Turingegatan','position': '59.199148,17.625546','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Uppsala Kungsgatan\": {'sourceId': 'SLB-Uppsala Kungsgatan','position': '59.199148,17.625546','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Gävle Södra Kungsgatan\": {'sourceId': 'SLB-Gavle Sodra Kungsgatan','position': '60.672235,17.146665','pm10': '','pm25': '','o3': '','no2': ''},\n        }\n        payload = {'sourceId': '','position': '','pm10': '','pm25': '','o3': '','no2': ''}\n        j = 0\n        for scr in scripts:\n            scrStr = str(scr)\n            if start in scrStr:\n                slbDataJs = str(find_between( scrStr, start, end))\n                slbDataJs = slbDataJs.replace(\"null\",\"None\")\n                slbData = ast.literal_eval(slbDataJs)\n                i = 0\n                for locationTitle in slbData[0]:\n                    try:\n                        position = SLB_LOCATIONS[locationTitle]\n                        pass\n                    except Exception as e:\n                        position = None\n                    if position:\n                        dataValue = slbData[-1][i]\n                        slbLocations[locationTitle][SLB_POLLUTANT[j]] = str(dataValue)\n                    i = i + 1\n                j = j + 1\n        for pl in slbLocations:\n            self.response.write(\"<p>\" + str(slbLocations[pl]) + \"</p>\")\n            taskqueue.add(url='/worker', params=slbLocations[pl])\n\nclass StateairIndia(webapp2.RequestHandler):\n    def get(self):\n        # SLB_LOCATIONS = {\n        #   \"Hornsgatan\": \"59.310014,18.050748\",\n        #   \"Folkungagatan\": \"59.312963,18.080363\",\n        #   \"Lilla Essingen (E4/E20)\": \"59.316569,18.026894\",\n        #   \"Södertälje Turingegatan\": \"59.35111,17.90213\",\n        #   \"Uppsala Kungsgatan\": \"59.311971,18.082123\",\n        #   \"Gävle Södra Kungsgatan\": \"59.313408,18.033371\"\n        # }\n        # SLB_POLLUTANT = [\"pm10\", \"pm25\", \"no2\", \"o3\"]\n        #\n        def find_between( s, first, last ):\n            try:\n                start = s.index( first ) + len( first )\n                end = s.index( last, start )\n                return s[start:end]\n            except ValueError:\n                return \"\"\n\n        url = \"http://newdelhi.usembassy.gov/dyn/airqualitydataemb/air-quality-indicator-proxy.html\"\n        headers = {'Accept':'text/html;charset=UTF-8','Content-Type':'text/html'}\n        result = urlfetch.fetch(\n            url,\n            headers=headers,\n            method='GET'\n        )\n        soup = BeautifulSoup(result.content, 'html.parser')\n        scripts = soup.find_all('script')\n        scrStr = str(scripts[1])\n\n        start = '$(\"#HD_Cval\").text(\"';\n        end = '\");'\n        if start in scrStr:\n            hyderabad = str(find_between( scrStr, start, end))\n            self.response.write(hyderabad)\n\n        indiaLocations = {\n          \"Hornsgatan\": {'sourceId': 'SLB-Hornsgatan','position': '59.317242,18.049891','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Hyderabad\": {'sourceId': 'UsConsulateHyderabad','position': '17.436926,78.489401','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Lilla Essingen (E4/E20)\": {'sourceId': 'SLB-Lilla Essingen','position': '59.325304,18.00296','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Södertälje Turingegatan\": {'sourceId': 'SLB-Sodertalje Turingegatan','position': '59.199148,17.625546','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Uppsala Kungsgatan\": {'sourceId': 'SLB-Uppsala Kungsgatan','position': '59.199148,17.625546','pm10': '','pm25': '','o3': '','no2': ''},\n          \"Gävle Södra Kungsgatan\": {'sourceId': 'SLB-Gavle Sodra Kungsgatan','position': '60.672235,17.146665','pm10': '','pm25': '','o3': '','no2': ''},\n        }\n        # payload = {'sourceId': '','position': '','pm10': '','pm25': '','o3': '','no2': ''}\n        # j = 0\n        # for scr in scripts:\n        #     scrStr = str(scr)\n        #     if start in scrStr:\n        #         slbDataJs = str(find_between( scrStr, start, end))\n        #         slbDataJs = slbDataJs.replace(\"null\",\"None\")\n        #         slbData = ast.literal_eval(slbDataJs)\n        #         i = 0\n        #         for locationTitle in slbData[0]:\n        #             try:\n        #                 position = SLB_LOCATIONS[locationTitle]\n        #                 pass\n        #             except Exception as e:\n        #                 position = None\n        #             if position:\n        #                 dataValue = slbData[-1][i]\n        #                 slbLocations[locationTitle][SLB_POLLUTANT[j]] = str(dataValue)\n        #             i = i + 1\n        #         j = j + 1\n        # for pl in slbLocations:\n        #     self.response.write(\"<p>\" + str(slbLocations[pl]) + \"</p>\")\n        #     taskqueue.add(url='/worker', params=slbLocations[pl])\n\n\n\ntableAqiIndex = [ range(0, 50, 1),range(51, 100, 1),range(101, 150, 1),range(151, 200, 1),range(201, 300, 1),range(301, 400, 1),range(401, 500, 1) ]\ntableCo = [ range(0, 44, 1),range(45, 94, 1),range(95, 124, 1),range(125, 154, 1),range(155, 304, 1),range(305, 404, 1),range(405, 504, 1) ]\ntableNo2 = [ range(0, 53, 1),range(54, 100, 1),range(101, 360, 1),range(361, 640, 1),range(650, 1240, 1),range(1250, 1640, 1),range(1650, 2040, 1) ]\ntableO3 = [ range(0, 53, 1),range(54, 100, 1),range(101, 360, 1),range(361, 640, 1),range(650, 1240, 1),range(1250, 1640, 1),range(1650, 2040, 1) ]\ntablePm10 = [ range(0, 54, 1),range(55, 154, 1),range(155, 254, 1),range(255, 354, 1),range(355, 424, 1),range(425, 504, 1),range(505, 604, 1) ]\ntablePm25 = [ range(0, 54, 1),range(55, 154, 1),range(155, 254, 1),range(255, 354, 1),range(355, 424, 1),range(425, 504, 1),range(505, 604, 1) ]\nindexLables = [\"Good\",\"Moderate\",\"Unhealthy for Sensitive Group\",\"Unhealthy\",\"Very Unhealthy\",\"Hazardous\",\"Hazardous\"]\n\n\ndef index(table, v, fac):\n\n    try:\n        row = [i for i,l in enumerate(table) if int(v*fac) in l][0]\n        bpLow = float(table[row][0])/fac\n        bpHigh = (float(table[row][len(table[row])-1]+1)/fac)\n        iLow = tableAqiIndex[row][0]\n        iHigh = tableAqiIndex[row][len(tableAqiIndex[row])-1]+1\n        index = (\n            (float(iHigh) - float(iLow)) /\n            (float(bpHigh) - float(bpLow))\n            ) * (float(v)-(float(bpLow))) + float(iLow)\n        return int(index)\n    except Exception, e:\n        print e\n        return 0\n\ndef aqi(values):\n\n    co=values[\"co\"]\n    pm10=values[\"pm10\"]\n    pm25=values[\"pm25\"]\n    o3=values[\"o3\"]\n    no2=values[\"no2\"]\n\n    #print \"%%%% AQI %%%%\"\n    #print values\n    #print \"ISDIG\"\n    #print pm10\n\n    f = 0\n    coIndex = 0\n    pm10Index = 0\n    pm25Index = 0\n    o3Index = 0\n    no2Index = 0\n\n    if co.replace('.','',1).isdigit():\n        coIndex = index(tableCo, float(co), 10)\n        f = f+1\n\n    if pm10.replace('.','',1).isdigit():\n    \tpm10Index = index(tablePm10, float(pm10), 1)\n    \tf = f+1\n\n    if pm25.replace('.','',1).isdigit():\n    \tpm25Index = index(tablePm25, float(pm25), 1)\n    \tf = f+1\n\n    if o3.replace('.','',1).isdigit():\n    \to3Index = index(tableO3, float(o3), 1)\n    \tf = f+1\n\n    # TODO: Check the factor\n    if no2.replace('.','',1).isdigit():\n    \tno2Index = index(tableNo2, float(no2), 1)\n    \tf = f+1\n\n    if f > 0:\n        return float((coIndex + pm10Index + pm25Index + o3Index + no2Index)/f)\n\n\n\nclass cache(object):\n    def __init__(self, fun):\n        #print \"init cache\"\n        self.fun = fun\n        self.cache = {}\n\n    def __call__(self, *args, **kwargs):\n        key  = str(args) + str(kwargs)\n        #print \"call cache\"\n\n        try:\n            #print \"return cache \" + key\n            return self.cache[key]\n        except KeyError:\n            self.cache[key] = rval = self.fun(*args, **kwargs)\n            return rval\n        except TypeError: # incase key isn't a valid key - don't cache\n            return self.fun(*args, **kwargs)\n\n@cache\ndef get_geolocation_url_src(url):\n    return urllib2.urlopen(url).read()\n\ndef getGeoValue(latlng, keys, valueType):\n    #\"123,123\", \"[country]\", \"short_name\"\n\n    url=GEOLOCATION_URL % latlng\n    data = memcache.get(latlng)\n    if data is None:\n        print \"getGeoValue - Data for \" + latlng + \" not in cache. Reading from API...\"\n        data = json.loads(get_geolocation_url_src(url))\n        memcache.add(latlng,data)\n\n    results = data[\"results\"]\n    def getGeoValueForAddress(res):\n        for key1 in keys:\n            for ac in res[\"address_components\"]:\n                if key1 in ac[\"types\"]:\n                    return ac[valueType]\n        return None\n\n\n    for key in keys:\n        for res in results:\n            if key in res[\"types\"]:\n                returnVal = getGeoValueForAddress(res)\n                return returnVal\n    return None\n\ndef getGeoFormattedAddress(latlng, keys):\n    url=GEOLOCATION_URL % latlng\n    data = memcache.get(latlng)\n    if data is None:\n        #print \"getGeoFormattedAddress - Data for \" + latlng + \" not in cache. Reading from API...\"\n        data = json.loads(get_geolocation_url_src(url))\n        memcache.add(latlng,data)\n\n\n    for key in keys:\n        for res in data[\"results\"]:\n            if key in res[\"types\"]:\n                return res[\"formatted_address\"]\n    return None\n\ndef getGeoPosition(latlng, keys):\n    url=GEOLOCATION_URL % latlng\n    data = memcache.get(latlng)\n    if data is None:\n        print \"getGeoPosition - Data for \" + latlng + \" not in cache. Reading from API...\"\n        data = json.loads(get_geolocation_url_src(url))\n        memcache.add(latlng,data)\n\n    for key in keys:\n        for res in data[\"results\"]:\n            if key in res[\"types\"]:\n                return str(res[\"geometry\"][\"location\"][\"lat\"]) + \",\" + str(res[\"geometry\"][\"location\"][\"lng\"])\n    return None\n\n\ndef getLocationContext(latlng):\n    context = {}\n    keyList = [\"neighborhood\",\"sublocality_level_2\",\"sublocality_level_1\",\"administrative_area_level_3\",\"colloquial_area\",\"postal_code\"]\n    try:\n        addrString = getGeoFormattedAddress(latlng, keyList).encode(\"utf-8\")\n        hoodPosition = getGeoPosition(latlng, keyList)\n        addrList = addrString.split(\", \")\n        zoneTitle = addrList[0].decode(\"utf-8\",\"ignore\")\n        addrList.remove(addrList[0])\n        addrList.remove(addrList[-1])\n        zoneSubTitle = \", \".join(addrList).decode(\"utf-8\")\n    \n        country = getGeoValue(latlng, [\"country\"], \"short_name\")\n        if country is None:\n            return None\n    \n        context[\"zoneTitle\"] = zoneTitle\n        context[\"zoneSubTitle\"] = zoneSubTitle\n        context[\"country\"] = country\n        context[\"zoneKey\"] = generateZoneKey(zoneTitle,zoneSubTitle,country)\n        context[\"position\"] = hoodPosition\n        return context\n    except Exception, e:\n        return None\n\ndef generateZoneKey(zoneTitle,zoneSubTitle,country):\n    zoneKeyInputString = zoneTitle + zoneSubTitle + country\n    zoneKey = hashlib.md5(zoneKeyInputString.encode('ascii', 'ignore').decode('ascii')).hexdigest()\n    return zoneKey\n\ndef test():\n    robj = {}\n    robj[\"country\"] = \"Sweden\"\n    return robj\n\n\"\"\"\nStores the actual measurement data from the different sources.\nTODO:\n    1. Should store the position labels.\n    2. Should not have to store the indexLabel. A dictionary will be included in the ZoneMessage.\n\"\"\"\nclass RegisterRecord(webapp2.RequestHandler):\n    def post(self): # should run at most 1/s\n        # print \"#1. Worker is registering \"\n        # Only needs timestamp, pm10, co, no2, position and sourceId as input.\n        # The rest should be calculated here.\n        \n        sourceId = self.request.get('sourceId')\n        logging.info(\"RECORD SOURCEID \" + sourceId)\n\n        pm10=self.request.get('pm10')\n        pm25=self.request.get('pm25')\n        o3=self.request.get('o3')\n        co=self.request.get('co')\n        no2=self.request.get('no2')\n\n        #print \"PM10: \" + pm10\n        #print \"CO: \" + co\n        #print \"NO2: \" + no2\n\n        aqiValue=aqi({\"co\":co,\"pm10\":pm10,\"pm25\":pm25,\"o3\":o3,\"no2\":no2})\n\n        if aqiValue is None:\n            print \"No AQI\"\n        else:\n            if not co.replace('.','',1).isdigit():\n                co = None\n            else:\n                co = float(co)\n\n            if not pm10.replace('.','',1).isdigit():\n                pm10 = None\n            else:\n                pm10 = float(pm10)\n\n            if not pm25.replace('.','',1).isdigit():\n                pm25 = None\n            else:\n                pm25 = float(pm25)\n\n            if not o3.replace('.','',1).isdigit():\n                o3 = None\n            else:\n                o3 = float(o3)\n\n            if not no2.replace('.','',1).isdigit() is None:\n                no2 = None\n            else:\n                no2 = float(no2)\n\n            latlng = self.request.get('position')\n\n            locationContext = getLocationContext(latlng)\n            \n            if (locationContext is None):\n                logging.warn(\"LocationContext returned none... \" + sourceId + \" latlng: \" + latlng)\n                return None\n                \n            zoneKey = locationContext.get('zoneKey')\n            zoneTitle = locationContext.get('zoneTitle')\n            zoneSubTitle = locationContext.get('zoneSubTitle')\n            country = locationContext.get('country')\n            position = locationContext.get('position')\n            timestamp = self.request.get('timestamp')\n            if not timestamp:\n                timestamp = calendar.timegm(time.gmtime())\n\n            \"\"\"\n            Now, generate the report...\n            1. Hitta ytterligare poster i samma zone\n            2. Rakna ut medeltal for index och de olika gaserna.\n            3. Kolla om det finns en rapport sedan tidigare.\n            4. spara historiska data\n            5. Berakna min24hr och max 24hr\n            \"\"\"\n            \n            reportDbRecord = Report(\n                name=zoneTitle + \" \" + zoneSubTitle,\n                key_name=zoneKey,\n                zoneKey=zoneKey\n            )            \n\n            \"\"\" Get the data newer than 1 hour \"\"\"\n            #res = db.GqlQuery(\"SELECT * FROM Records WHERE zoneKey='\" + zoneKey + \"' AND timestamp >= :1\", datetime.datetime.now() - datetime.timedelta(hours = 6))\n            #res = db.GqlQuery(\"SELECT * FROM Records WHERE zoneKey='\" + zoneKey + \"'\")\n            \n            recordQuery = Records.all()\n            recordQuery.ancestor(reportDbRecord)\n\n            \"\"\" Create a list of all stations and history values \"\"\"\n            avrIndex = 0\n            resCount = 0\n            stationsDict = {}\n            historyDict = {}\n            indexArr = []\n            for r in recordQuery.run():\n                #logging.info(\"### RECORD SOURCEID \" + r.sourceId)\n                historyDate = r.timestamp.strftime('%Y-%m-%d')\n                indexArr = historyDict.get(historyDate, [0.0])\n                indexArr.append(r.index)\n                historyDict[historyDate] = indexArr\n                avrIndex = avrIndex + r.index\n                stationsDict[r.sourceId] = str(r.position)\n                resCount = resCount + 1\n\n            stations = []\n            for key, value in stationsDict.iteritems():\n                temp = {}\n                temp[\"sourceId\"] = key\n                temp[\"position\"] = value\n\n                stations.append(temp)\n\n            \"\"\" Add a proper locale. For now all languages are english \"\"\"\n            class Location(): pass\n            location = Location()\n            location.country=country.upper()\n            location.language=\"en\"\n\n\n            \"\"\" Create a array of history records. Each record contains the date and the index for that date.  \"\"\"\n            historyArr = []\n            class HistoricDate():\n                def __init__(self, dict):\n                    self.__dict__ = dict\n\n            for key, value in historyDict.iteritems():\n                historyArr.append(HistoricDate({'date' : key, 'index':reduce(lambda x, y: x + y, value) / (len(value)-1)}))\n\n            \"\"\" Create the zone-detail object that will be persisted as a report for use in the zones API \"\"\"\n            class ZoneDetail():\n                def to_JSON(self):\n                    return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True)\n\n            zd = ZoneDetail()\n            zd.zoneKey=zoneKey\n            zd.title=zoneTitle\n            zd.subtitle=zoneSubTitle\n            zd.stations=stations\n            try:\n                zd.numberOfMeasurements=str(resCount)\n                if resCount > 0:\n                    zd.index=avrIndex/resCount\n                else:\n                    #zd.index=float(res[0].index)\n                    zd.index=0\n            except Exception, e:\n            \tprint \"numberOfMeasurements and index set to 0\"\n                zd.numberOfMeasurements = 0\n                zd.index = 0\n\n            zd.co=co\n            zd.no2=no2\n            zd.pm10=pm10\n            zd.pm25=pm25\n            zd.o3=o3\n            zd.location=location\n            zd.position=position\n            zd.history=historyArr\n            zd.min24Hr=1.0\n            zd.max24Hr=1.0\n\n\n\n            \n            # recordQuery = Records.all()\n            # recordQuery.ancestor(reportDbRecord)\n            # for rrr in recordQuery.run(limit=5):\n            #     logging.info(\"### RECORD \" + rrr.sourceId)\n                    \n            reportDbRecord.report=zd.to_JSON()\n            reportDbRecord.put()\n\n            rec=Records(\n                parent=reportDbRecord,\n                timestamp=datetime.datetime.fromtimestamp(float(timestamp)),\n                pm10=pm10,\n                pm25=pm25,\n                o3=o3,\n                co=co,\n                no2=no2,\n                zoneKey=zoneKey,\n                # The index should be calculated here\n                #index=self.request.get('index'),\n                index=aqiValue,\n                # TODO: Do a lookup to google\n                position=self.request.get('position'),\n                positionLabels=zoneTitle,\n                sourceId=self.request.get('sourceId'),\n            )\n\n            rec.put()\n\n            # Save data in fusion table.\n            # scopes = ['https://www.googleapis.com/auth/fusiontables']\n            #credentials = ServiceAccountCredentials.from_json_keyfile_name('airupBackend-b120f4cbc1a7.json', scopes)\n            #credentials = ServiceAccountCredentials.from_json_keyfile_name('airupdata-297e9f1e1562.json', scopes)\n            #fusiontablesadmin = build('fusiontables', 'v2', credentials=credentials)\n            #fusiontablesadmin.query().sql(sql=\"INSERT INTO 1VQ8VQZwKY7zjrTqAxQTtlYdt18bjsbU7Gx4_nyK7 ('Source ID','index','Date','Pos') VALUES ('\" + self.request.get('sourceId') + \"', \" + aqiValue + \", '\" + datetime.datetime.fromtimestamp(float(timestamp)) + \"', '\" + self.request.get('position') + \"') \").execute()\n\n\n\n            # myKey = db.Key.from_path('Report', zoneKey)\n            # rec = db.get(myKey)\n            # rec.report = zd.to_JSON()\n            # rec.put()\n\n\n\nclass Index(webapp2.RequestHandler):\n    def get(self):\n\t\ttemplate_values = {\n\t\t\t'greetings': 'zxc',\n\t\t}\n\t\ttemplate = JINJA_ENVIRONMENT.get_template('index.html')\n\t\tself.response.write(template.render(template_values))\n\napp = webapp2.WSGIApplication([\n        ('/worker', RegisterRecord),\n        ('/bot', Bot),\n        ('/linkoping', Linkoping),\n        ('/airnow', Airnow),\n        ('/india', StateairIndia),\n        ('/gbg1', Goteborg),\n        ('/umea1', Umea),\n        ('/hamburg1', Hamburg1),\n        ('/sthlm', Sthlm),\n        ('/eaa',Eaa),\n        ('/foobot',Foobot),\n        ('/stateair',Stateair),\n        ('/submitToQueue',SubmitToQueue),\n        ('/index.html', Index)\n    ], debug=True)\n","undoManager":{"mark":-2,"position":-1,"stack":[]},"ace":{"folds":[],"scrolltop":240,"scrollleft":0,"selection":{"start":{"row":38,"column":0},"end":{"row":38,"column":93},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":17,"state":"qqstring3","mode":"ace/mode/python"}},"timestamp":1487153797057}